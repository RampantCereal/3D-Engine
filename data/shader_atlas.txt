//example of some shaders compiled
flat basic.vs flat.fs
texture basic.vs texture.fs
depth quad.vs depth.fs
multi basic.vs multi.fs
phong basic.vs phong.fs
pbr basic.vs pbr.fs
gBuffers basic.vs textureBuffer.fs
deferred quad.vs deferred.fs
deferred_pbr quad.vs deferred_pbr.fs
ssao quad.vs ssao.fs
blur quad.vs blur.fs
probe basic.vs sh.fs
skybox basic.vs skybox.fs
reflectionProbe basic.vs reflection.fs
deferredReflections quad.vs deferred_reflections.fs
volumetricDirectional quad.vs volumetric.fs
decals basic.vs decals.fs

\decals.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;


uniform sampler2D u_texture;
uniform sampler2D u_depth_texture;
uniform float u_time;

uniform vec2 u_iRes;
uniform vec3 u_camera_position;
uniform mat4 u_model;
uniform mat4 u_imodel;
uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;

layout(location = 0) out vec4 FragColor;


void main()
{
	//extract uvs from pixel screenpos
	//vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; 
	vec2 uv = gl_FragCoord.xy*u_iRes; 

	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	if(depth >= 1.0)
		discard;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;
	//now do your illumination using worldpos and the normal...

	vec3 decal_pos = (u_imodel * vec4(worldpos,1.0)).xyz;
	vec2 uv_decal = decal_pos.xz *0.5 + vec2(0.5);
	if(uv_decal.x < 0.0 || uv_decal.x > 1.0 || uv_decal.y < 0.0 || uv_decal.y > 1.0 )
		discard;
	vec4 color = texture(u_texture, uv_decal);


	FragColor = color;
	
}


\volumetric.fs


#version 330 core

uniform sampler2D u_depth_texture;
uniform sampler2D u_shadow_map;
uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform mat4 u_shadow_viewprojection;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;
uniform float u_shadow_bias;
uniform vec3 u_light_color;
uniform vec3 u_rand;
uniform sampler2D u_noise_texture;

in vec2 v_uv;


layout(location = 0) out vec4 FragColor;



void main()
{
	//extract uvs from pixel screenpos
	vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; 

	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;
	//now do your illumination using worldpos and the normal...

	vec3 raydir =  (worldpos - u_camera_position);

	float noise = texture(u_noise_texture, uv + u_rand.xy).x;

	const int SAMPLES = 64;
	raydir /= float(SAMPLES);

	vec3 current_pos = u_camera_position + noise * raydir;

	

	vec3 color = vec3(0.0);
	float total_density = 0.0;


	for(int i = 0; i < SAMPLES; i++){

		//////////////////////////////////////////////////////////////////////////////////// shadows
		//project our 3D position to the shadowmap
		vec4 proj_pos = u_shadow_viewprojection * vec4(current_pos,1.0);

		//from homogeneous space to clip space
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		
		//from clip space to uv space
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);

		//get point depth (from -1 to 1)
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;


		//normalize from [-1..+1] to [0..+1]
		real_depth = real_depth * 0.5 + 0.5;

		//read depth from depth buffer in [0..+1]
		float shadow_depth = texture( u_shadow_map, shadow_uv).x;

		//compute final shadow factor by comparing
		float shadow_factor = 1.0;
		if( shadow_depth < real_depth)
			shadow_factor = 0.0;

		//it is outside on the sides
		if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			shadow_factor =  1.0;

		//it is before near or behind far plane
		if(real_depth < 0.0 || real_depth > 1.0)
			shadow_factor =  1.0;

		///////////////////////////////////////////////////////////////////////////////////

		color += shadow_factor * u_light_color;
		total_density += 0.001*shadow_factor;
		current_pos += raydir;
	}

	FragColor = vec4(color,total_density);



}

\deferred_reflections.fs

#version 330 core

uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_depth_texture;
uniform samplerCube u_environment_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform bool u_reflect_skybox;
float metalness;
float roughness;

vec3 R;

//camera
uniform vec3 u_camera_position;

layout(location = 0) out vec4 FragColor;


void main()
{
	//extract uvs from pixel screenpos
	vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; 
	vec3 color = texture( u_color_texture, uv ).xyz;
	
	metalness = texture( u_color_texture, uv ).w;
	if(metalness <0.5)
		discard;
	roughness = texture( u_normal_texture, uv ).w;

	//normals must be converted from 0..1 to -1..+1
	vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	N = normalize(N); //always normalize in case of data loss

	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	if(depth == 1.0)
		discard;

	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;
	//now do your illumination using worldpos and the normal...

	vec3 V = normalize( u_camera_position - worldpos );
	if(u_reflect_skybox)
		R = reflect( V, N );
	else
		R = reflect( -V, N );

	float mip_level = roughness * 4.0;
	vec3 spec;
	if(u_reflect_skybox)
		spec = color * textureLod( u_environment_texture, R, mip_level ).xyz * 0.4 ;
	else
		spec = color * textureLod( u_environment_texture, R, mip_level ).xyz;

	//vec3 spec = color * textureLod( u_environment_texture, R, mip_level ).xyz;


	//FragColor = texture( u_environment_texture, R );
	FragColor = vec4(spec,metalness);



}

\reflection.fs

#version 330 core

in vec3 v_world_position;
in vec3 v_normal;

uniform samplerCube u_texture;
uniform vec3 u_camera_pos;

out vec4 FragColor;

void main()
{
	vec3 N = normalize(v_normal);
	vec3 V = normalize( u_camera_pos -v_world_position );
	vec3 R = reflect(V, N);

	
	FragColor = textureLod( u_texture, -R, 0.0 ) * 1.0;
}

\skybox.fs

#version 330 core

in vec3 v_world_position;

uniform samplerCube u_texture;
uniform vec3 u_camera_pos;

out vec4 FragColor;

void main()
{
	vec3 V = normalize( u_camera_pos -v_world_position );

	//FragColor = texture( u_texture, V );
	FragColor = textureLod( u_texture, V, 0.0 ) * 0.4;
}


\sh.fs

#version 330 core

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}

uniform mat4 u_model;
uniform mat4 u_viewprojection;
uniform vec3 u_camera_position;

uniform vec3 u_coeffs[9];
in vec3 v_normal;

SH9Color coeffs;

out vec4 FragColor;

void main()
{
	coeffs.c = u_coeffs;
	FragColor = vec4(ComputeSHIrradiance(v_normal, coeffs),1.0);
}

\basic.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_uv;
in vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;
out vec4 v_color;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_uv;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\quad.vs

#version 330 core

in vec3 a_vertex;
in vec2 a_uv;
out vec2 v_uv;

void main()
{	
	v_uv = a_uv;
	gl_Position = vec4( a_vertex, 1.0 );
}


\flat.fs

#version 330 core

uniform vec4 u_color;

out vec4 FragColor;

void main()
{
	FragColor = u_color;
}


\texture.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

out vec4 FragColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;

	color *= texture( u_texture, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	FragColor = color;
}

\textureBuffer.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform sampler2D u_rough_metal;
uniform float u_time;
uniform float u_alpha_cutoff;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;

float metal;
float rough;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv );
	metal = texture(u_rough_metal, uv).z;
	rough = texture(u_rough_metal, uv).y;
	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize( v_normal );

	FragColor = vec4(color.xyz, metal);
	NormalColor = vec4(v_normal*0.5 + vec3(0.5),rough);
	//NormalColor = vec4(v_normal,1.0);

}

\multi.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	vec3 N = normalize(v_normal);

	FragColor = color;
	NormalColor = vec4(N,1.0);
}


\depth.fs

#version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
in vec2 v_uv;
out vec4 FragColor;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	FragColor = vec4(color);
}


\instanced.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_uv;

in mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_uv;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\phong.fs

#version 330 core

in vec3 v_position; //position in local coords
in vec3 v_world_position; //position in world coord
in vec3 v_normal; //normal in the pixel
in vec2 v_uv; //texture coordinates
in vec4 v_color;



uniform vec3 u_camera_position; //camera eye

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform vec3 u_ambient_light;
uniform vec3 u_light_position;
uniform vec3 u_light_color;
uniform float u_light_type;

vec3 light_color = u_light_color;
//point
uniform float u_light_maxdist;

//shadows
uniform sampler2D u_shadow_map;
uniform mat4 u_shadow_viewprojection;
uniform float u_shadow_bias;


//spot
uniform vec3 u_spotDirection;  
uniform float u_spotCosineCutoff; 
uniform float u_spotExponent;

out vec4 FragColor;

float att_factor;
void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv );

	if(color.a < u_alpha_cutoff)
		discard;

	

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	//lets add the ambient light first
	light += u_ambient_light;

	//very important to normalize as they come
	//interpolated so normalization is lost
	vec3 N = normalize( v_normal );

	//here we store the L vector
	vec3 L;
	float spotFactor;

	//depending on the light type...
	if( u_light_type == 0 ) //directional  light
	{
		L = u_light_position;
		
	}
	else //point and spot light
	{
		//vector from the point to the light
		L = u_light_position - v_world_position;
	
		//we ignore the light distance for now
		L = normalize(L);


		//compute distance FOR ATTENUANTION
		float light_distance = length(u_light_position - v_world_position );

		//compute a linear attenuation factor
		att_factor = u_light_maxdist - light_distance;

		//normalize factor
		att_factor /= u_light_maxdist;

		//ignore negative values
		att_factor = max( att_factor, 0.0 );

		// spot only
		if(u_light_type == 2){ 

			vec3 D = normalize(u_spotDirection);  // unit vector!
    		float spotCosine = dot(D,-L);

    		if (spotCosine >= u_spotCosineCutoff) { 
        		spotFactor = pow(spotCosine,u_spotExponent);
    		}
    		else { // The point is outside the cone of light from the spotlight.
        		spotFactor = 0; // The light will add no color to the point.
    		}

			light_color *= spotFactor;
		}
	}

	//////////////////////////////////////////////////////////////////////////////////// shadows
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewprojection * vec4(v_world_position,1);

	//from homogeneous space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;
	
	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;


	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;

	//read depth from depth buffer in [0..+1]
	float shadow_depth = texture( u_shadow_map, shadow_uv).z;

	//compute final shadow factor by comparing
	float shadow_factor = 1.0;
	if( shadow_depth < real_depth && (u_light_type == 2 || u_light_type == 0))
		shadow_factor = 0.0;

	//it is outside on the sides
	if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		shadow_factor =  1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		shadow_factor =  1.0;

	///////////////////////////////////////////////////////////////////////////////////

	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );

	//store the amount of diffuse light
	if(u_light_type == 1  ){
		light += (NdotL * light_color)*att_factor;
	}
	else{
		light += NdotL * light_color* shadow_factor;
	}



	//apply to final pixel color
	color.xyz *= light;

	FragColor = color;


}

\deferred.fs

#version 330 core


uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_ao_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

//pass here all the uniforms required for illumination...
uniform vec3 u_ambient_light;
uniform vec3 u_light_position;
uniform vec3 u_light_color;
uniform float u_light_type;

//shadow uniforms
uniform sampler2D u_shadow_map;
uniform mat4 u_shadow_viewprojection;
uniform float u_shadow_bias;

//point light
uniform float u_light_maxdist;

//spot light
uniform vec3 u_spotDirection;  
uniform float u_spotCosineCutoff; 
uniform float u_spotExponent;

//bg
uniform vec3 u_bg_color;

//variables 
float att_factor;
float spotFactor;
float shadow_factor;
vec3 light_color = u_light_color;

layout(location = 0) out vec4 FragColor;

void main()
{
//extract uvs from pixel screenpos
	vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; 
	vec3 color = texture( u_color_texture, uv ).xyz;

	//normals must be converted from 0..1 to -1..+1
	vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	N = normalize(N); //always normalize in case of data loss

	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;
	//now do your illumination using worldpos and the normal...

	
	


	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	//here we store the L vector
	vec3 L;
	
	L = (u_light_position - worldpos);
	float dist = length(L);
	L/= dist;

	if(u_light_type == 0){ //first pass directional + ambient
		//we need the uv for the pixel in screen position
		vec2 screenuv = gl_FragCoord.xy * u_iRes;

		//read the ao_factor for this pixel
		float ao_factor = texture( u_ao_texture, screenuv ).x;

		//we could play with the curve to have more control
		ao_factor = pow( ao_factor, 3.0 );

		//lets add the ambient light first
		light += u_ambient_light*ao_factor;

	}
	else //point and spot light
	{

		//compute a linear attenuation factor
		att_factor = u_light_maxdist - dist;

		//normalize factor
		att_factor /= u_light_maxdist;

		//ignore negative values
		att_factor = max( att_factor, 0.0 );

		// spot only
		if(u_light_type == 2){ 

			vec3 D = normalize(u_spotDirection);  // unit vector!
    		float spotCosine = dot(D,-L);

    		if (spotCosine >= u_spotCosineCutoff) { 
        		spotFactor = pow(spotCosine,u_spotExponent);
    		}
    		else { // The point is outside the cone of light from the spotlight.
        		spotFactor = 0; // The light will add no color to the point.
    		}

			light_color *= spotFactor;
		}
	}

	//////////////////////////////////////////////////////////////////////////////////// shadows
		//project our 3D position to the shadowmap
		vec4 proj_pos = u_shadow_viewprojection * vec4(worldpos,1);

		//from homogeneous space to clip space
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		
		//from clip space to uv space
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);

		//get point depth (from -1 to 1)
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;


		//normalize from [-1..+1] to [0..+1]
		real_depth = real_depth * 0.5 + 0.5;

		//read depth from depth buffer in [0..+1]
		float shadow_depth = texture( u_shadow_map, shadow_uv).z;

		//compute final shadow factor by comparing
		shadow_factor = 1.0;
		if( shadow_depth < real_depth && (u_light_type == 2 || u_light_type == 0))
			shadow_factor = 0.0;

		//it is outside on the sides
		if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			shadow_factor =  1.0;

		//it is before near or behind far plane
		if(real_depth < 0.0 || real_depth > 1.0)
			shadow_factor =  1.0;

		///////////////////////////////////////////////////////////////////////////////////

	//compute how much is aligned
	float NdotL = dot(N,L);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );


	//store the amount of diffuse light
	if(u_light_type == 0 || u_light_type == 2){
		light += NdotL * light_color * shadow_factor;
	}
	if(u_light_type == 1  ){
		light += (NdotL * light_color)*att_factor;
	}
	
	

	//apply to final pixel color
	if(depth != 1.0)
		color.xyz *= light;
	else
		discard;

	FragColor = vec4(color,1.0);
}


\pbr.fs

#version 330 core

#define PI 3.1415926535897932384626433832795

in vec3 v_position; //position in local coords
in vec3 v_world_position; //position in world coord
in vec3 v_normal; //normal in the pixel
in vec2 v_uv; //texture coordinates
in vec4 v_color;



uniform vec3 u_camera_position; //camera eye

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform sampler2D u_roughness_metalness;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform vec3 u_ambient_light;
uniform vec3 u_light_position;
uniform vec3 u_light_color;
uniform float u_light_type;

vec3 light_color = u_light_color;
//point
uniform float u_light_maxdist;

//shadows
uniform sampler2D u_shadow_map;
uniform mat4 u_shadow_viewprojection;
uniform float u_shadow_bias;

//used variables
float metalness;
float roughness;

//spot
uniform vec3 u_spotDirection;  
uniform float u_spotCosineCutoff; 
uniform float u_spotExponent;

out vec4 FragColor;

//functions

// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}

// Fresnel term with colorized fresnel
vec3 F_Schlick( const in float VoH, const in vec3 f0)
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

// Normal Distribution Function using GGX Distribution
float D_GGX (	const in float NoH, 
const in float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}

//this is the cook torrance specular reflection model
vec3 specularBRDF( float roughness, vec3 f0, float NoH, float NoV, float NoL, float LoH )
{
float a = roughness * roughness;

// Normal Distribution Function
float D = D_GGX( NoH, a );

	// Fresnel Function
	vec3 F = F_Schlick( LoH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}



float att_factor;
void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv );
	metalness = texture(u_roughness_metalness, uv).z;
	roughness = texture(u_roughness_metalness, uv).y;

	if(color.a < u_alpha_cutoff)
		discard;

	

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	//lets add the ambient light first
	light += u_ambient_light;

	//very important to normalize as they come
	//interpolated so normalization is lost
	vec3 N = normalize( v_normal );

	//here we store the L vector
	vec3 L;
	float spotFactor;

	//depending on the light type...
	if( u_light_type == 0 ) //directional  light
	{
		L = u_light_position;
		
	}
	else //point and spot light
	{
		//vector from the point to the light
		L = u_light_position - v_world_position;
	
		//we ignore the light distance for now
		L = normalize(L);


		//compute distance FOR ATTENUANTION
		float light_distance = length(u_light_position - v_world_position );

		//compute a linear attenuation factor
		att_factor = u_light_maxdist - light_distance;

		//normalize factor
		att_factor /= u_light_maxdist;

		//ignore negative values
		att_factor = max( att_factor, 0.0 );

		// spot only
		if(u_light_type == 2){ 

			vec3 D = normalize(u_spotDirection);  // unit vector!
    		float spotCosine = dot(D,-L);

    		if (spotCosine >= u_spotCosineCutoff) { 
        		spotFactor = pow(spotCosine,u_spotExponent);
    		}
    		else { // The point is outside the cone of light from the spotlight.
        		spotFactor = 0; // The light will add no color to the point.
    		}

			light_color *= spotFactor;
		}
	}

	//////////////////////////////////////////////////////////////////////////////////// shadows
	//project our 3D position to the shadowmap
	vec4 proj_pos = u_shadow_viewprojection * vec4(v_world_position,1);

	//from homogeneous space to clip space
	vec2 shadow_uv = proj_pos.xy / proj_pos.w;
	
	//from clip space to uv space
	shadow_uv = shadow_uv * 0.5 + vec2(0.5);

	//get point depth (from -1 to 1)
	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;


	//normalize from [-1..+1] to [0..+1]
	real_depth = real_depth * 0.5 + 0.5;

	//read depth from depth buffer in [0..+1]
	float shadow_depth = texture( u_shadow_map, shadow_uv).z;

	//compute final shadow factor by comparing
	float shadow_factor = 1.0;
	if( shadow_depth < real_depth && (u_light_type == 2 || u_light_type == 0))
		shadow_factor = 0.0;

	//it is outside on the sides
	if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		shadow_factor =  1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		shadow_factor =  1.0;

	///////////////////////////////////////////////////////////////////////////////////

	//Vectors
	vec3 V = normalize(u_camera_position- v_world_position);
	vec3 H = normalize(V+L);
	//dotProducts
	float NdotL = dot(N,L);
	float NdotH = dot(N,H);
	float NdotV = dot(N,V);
	float LdotH = dot(L,H);

	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	NdotH = clamp( NdotH, 0.0, 1.0 );
	NdotV = clamp( NdotV, 0.0, 1.0 );
	LdotH = clamp( LdotH, 0.0, 1.0 );

	
	
	///////////////////////////////////////////////////////////////////////////////////////PBR
		//we compute the reflection in base to the color and the metalness
		vec3 f0 = color.xyz * metalness + (vec3(0.5) * (1.0-metalness));

		//metallic materials do not have diffuse
		vec3 diffuseColor = (1.0 - metalness) * color.xyz;

		// Here we use the Burley, but you can replace it by the Lambert.
		// linearRoughness = squared roughness
		vec3 Fd_d = diffuseColor * NdotL; 

		//compute the specular
		vec3 Fr_d = specularBRDF(  roughness, f0, NdotH, NdotV, NdotL, LdotH);

		//add diffuse and specular reflection
		vec3 direct = Fr_d + Fd_d;

		vec3 lightParams;

		if(u_light_type == 1  ){
			lightParams = light_color * att_factor ;
			//light += (NdotL * light_color)*att_factor;
		}
		else{
			lightParams = light_color  * shadow_factor;
			//light += NdotL * light_color* shadow_factor;
		}

		//modulate direct light by light received
		light += direct * lightParams;

	///////////////////////////////////////////////////////////////////////////////////////
	//apply to final pixel color
	color.xyz *= light;

	FragColor = color;

}


\deferred_pbr.fs

#version 330 core

#define PI 3.1415926535897932384626433832795

uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_depth_texture;
uniform sampler2D u_ao_texture;
uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;

//pass here all the uniforms required for illumination...
uniform vec3 u_ambient_light;
uniform vec3 u_light_position;
uniform vec3 u_light_color;
uniform float u_light_type;

//shadow uniforms
uniform sampler2D u_shadow_map;
uniform mat4 u_shadow_viewprojection;
uniform float u_shadow_bias;

//point light
uniform float u_light_maxdist;

//spot light
uniform vec3 u_spotDirection;  
uniform float u_spotCosineCutoff; 
uniform float u_spotExponent;

//irradiance
uniform sampler2D u_irr_texture;
uniform vec3 u_irr_start;
uniform vec3 u_irr_end;
uniform vec3 u_irr_dim;
uniform float u_irr_normal_distance;
uniform vec3 u_irr_delta;
uniform float u_num_probes;
uniform bool u_use_irradiance;

//camera
uniform vec3 u_camera_position;


//variables 
float att_factor;
float spotFactor;
float shadow_factor;
vec3 light_color = u_light_color;
float metalness;
float roughness;

layout(location = 0) out vec4 FragColor;

//functions

// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}

// Fresnel term with colorized fresnel
vec3 F_Schlick( const in float VoH, const in vec3 f0)
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}

// Normal Distribution Function using GGX Distribution
float D_GGX (	const in float NoH, 
const in float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}

//this is the cook torrance specular reflection model
vec3 specularBRDF( float roughness, vec3 f0, float NoH, float NoV, float NoL, float LoH )
{
float a = roughness * roughness;

// Normal Distribution Function
float D = D_GGX( NoH, a );

	// Fresnel Function
	vec3 F = F_Schlick( LoH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}

//irradiance functions
const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}



void main()
{
	//extract uvs from pixel screenpos
	vec2 uv = (gl_FragCoord.xy + vec2(0.5)) * u_iRes.xy; 
	vec3 color = texture( u_color_texture, uv ).xyz;
	
	metalness = texture( u_color_texture, uv ).w;
	roughness = texture( u_normal_texture, uv ).w;

	//normals must be converted from 0..1 to -1..+1
	vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	N = normalize(N); //always normalize in case of data loss

	//reconstruct world position from depth and inv. viewproj
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;
	//now do your illumination using worldpos and the normal...

	////////////////////////////////////////////////////////////////irradiance calculations START
	vec3 irradiance;
	if(u_use_irradiance){

		//computing nearest probe index based on world position
		vec3 irr_range = u_irr_end - u_irr_start;
		vec3 irr_local_pos = clamp( worldpos - u_irr_start 
		+ N * u_irr_normal_distance, //offset a little
		vec3(0.0), irr_range );

		//convert from world pos to grid pos
		vec3 irr_norm_pos = irr_local_pos / u_irr_delta;

		//round values as we cannot fetch between rows for now
		vec3 local_indices = round( irr_norm_pos );

		//compute in which row is the probe stored
		float row = local_indices.x + 
		local_indices.y * u_irr_dim.x + 
		local_indices.z * u_irr_dim.x * u_irr_dim.y;

		//find the UV.y coord of that row in the probes texture
		float row_uv = (row + 1.0) / (u_num_probes + 1.0);

		SH9Color sh;

		//fill the coefficients
		const float d_uvx = 1.0 / 9.0;
		for(int i = 0; i < 9; ++i)
		{
			vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
			sh.c[i] = texture( u_irr_texture, coeffs_uv).xyz;
		}

		//now we can use the coefficients to compute the irradiance
		irradiance = ComputeSHIrradiance( N, sh );

	}///////////////////////////////////////////////////////////////irradiance calculations END

	//here we can store the total amount of light
	vec3 light = vec3(0.0);

	//here we store the L vector
	vec3 L;
	L = (u_light_position - worldpos);
	float dist = length(L);
	L/= dist;

	if(u_light_type == 0){ //first pass directional + ambient

		//we need the uv for the pixel in screen position
		vec2 screenuv = gl_FragCoord.xy * u_iRes;

		//read the ao_factor for this pixel
		float ao_factor = texture( u_ao_texture, screenuv ).x;
		
		//we could play with the curve to have more control
		ao_factor = pow( ao_factor, 3.0 );
		
		//lets add the ambient light first
		
		if(!u_use_irradiance){
			light += u_ambient_light*ao_factor;
		}
		else{
			light += (u_ambient_light+irradiance)*ao_factor;
		}
		
	}
	else //point and spot light
	{
		//compute a linear attenuation factor
		att_factor = u_light_maxdist - dist;
		
		//normalize factor
		att_factor /= u_light_maxdist;
		
		//ignore negative values
		att_factor = max( att_factor, 0.0 );
		
		// spot only
		if(u_light_type == 2){ 
			vec3 D = normalize(u_spotDirection);  // unit vector!
    		
			float spotCosine = dot(D,-L);
    		if (spotCosine >= u_spotCosineCutoff) { 
        		spotFactor = pow(spotCosine,u_spotExponent);
    		}
    		else { // The point is outside the cone of light from the spotlight.
        		spotFactor = 0; // The light will add no color to the point.
    		}
			light_color *= spotFactor;
		}
	}

	//////////////////////////////////////////////////////////////////////////////////// shadows
		//project our 3D position to the shadowmap
		vec4 proj_pos = u_shadow_viewprojection * vec4(worldpos,1);
		
		//from homogeneous space to clip space
		vec2 shadow_uv = proj_pos.xy / proj_pos.w;
		
		//from clip space to uv space
		shadow_uv = shadow_uv * 0.5 + vec2(0.5);
		
		//get point depth (from -1 to 1)
		float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;
		
		//normalize from [-1..+1] to [0..+1]
		real_depth = real_depth * 0.5 + 0.5;
		
		//read depth from depth buffer in [0..+1]
		float shadow_depth = texture( u_shadow_map, shadow_uv).z;
		
		//compute final shadow factor by comparing
		shadow_factor = 1.0;
		if( shadow_depth < real_depth && (u_light_type == 2 || u_light_type == 0))
			shadow_factor = 0.0;
		
		//it is outside on the sides
		if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
			shadow_factor =  1.0;
		
		//it is before near or behind far plane
		if(real_depth < 0.0 || real_depth > 1.0)
			shadow_factor =  1.0;

		///////////////////////////////////////////////////////////////////////////////////

	//Vectors
	vec3 V = normalize(u_camera_position - worldpos);
	vec3 H = normalize(V+L);
	
	//dotProducts
	float NdotL = dot(N,L);
	float NdotH = dot(N,H);
	float NdotV = dot(N,V);
	float LdotH = dot(L,H);
	
	//light cannot be negative (but the dot product can)
	NdotL = clamp( NdotL, 0.0, 1.0 );
	NdotH = clamp( NdotH, 0.0, 1.0 );
	NdotV = clamp( NdotV, 0.0, 1.0 );
	LdotH = clamp( LdotH, 0.0, 1.0 );
	
	//we compute the reflection in base to the color and the metalness
	vec3 f0 = color.xyz * metalness + (vec3(0.5) * (1.0-metalness));
	
	//metallic materials do not have diffuse
	vec3 diffuseColor = (1.0 - metalness) * color.xyz;
	
	// Here we use the Burley, but you can replace it by the Lambert.
	// linearRoughness = squared roughness
	vec3 Fd_d = diffuseColor * NdotL; 
	
	//compute the specular
	vec3 Fr_d = specularBRDF(  roughness, f0, NdotH, NdotV, NdotL, LdotH);
	
	//add diffuse and specular reflection
	vec3 direct = Fr_d + Fd_d;
	vec3 lightParams;
	
	//store the amount of diffuse light
	if(u_light_type == 0 || u_light_type == 2){
		lightParams = light_color  * shadow_factor;
	}
	if(u_light_type == 1  ){
		lightParams = light_color * att_factor ;
		//light += (NdotL * light_color)*att_factor;
	}
	
	//modulate direct light by light received
	light += direct * lightParams;
	
	//apply to final pixel color
	if(depth != 1.0)
		color.xyz *= light;
	else
		discard;
	FragColor = vec4(color,1.0);
}

\ssao.fs

#version 330 core

uniform sampler2D u_depth_texture; //depth buffer
uniform sampler2D u_normal_texture; //normal buffer

uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform vec3 u_camera_position;

uniform vec2 u_iRes;

uniform vec3 u_points[32];


in vec2 v_uv;
out vec4 FragColor;


const int samples = 32;
int num = samples; //num samples that passed the are outside

//from this github repo
mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx( p );
	vec3 dp2 = dFdy( p );
	vec2 duv1 = dFdx( uv );
	vec2 duv2 = dFdy( uv );
	
	// solve the linear system
	vec3 dp2perp = cross( dp2, N );
	vec3 dp1perp = cross( N, dp1 );
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
	// construct a scale-invariant frame 
	float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
	return mat3( T * invmax, B * invmax, N );
}


void main()
{
	//we want to center the sample in the center of the pixel
	vec2 uv = v_uv + u_iRes * 0.5;

	//read depth from depth buffer
	float depth = texture( u_depth_texture, uv ).x;
	vec3 normal = texture(u_normal_texture, uv).xyz;

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		FragColor = vec4(1.0);
		return;
	}

	//create screenpos with the right depth
	vec4 screen_position = vec4(uv*2.0 - vec2(1.0), depth*2.0 - 1.0,1.0);

	//reproject
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	//to create the matrix33 to convert from tangent to world
	mat3 rotmat = cotangent_frame( normal, worldpos, uv );


	//for every sample around the point
	for( int i = 0; i < samples; ++i )
	{
		//compute is world position using the random
		vec3 p = worldpos + (rotmat*u_points[i]) * 10.0;


		//find the uv in the depth buffer of this point
		vec4 proj = u_viewprojection * vec4(p,1.0);
		proj.xy /= proj.w; //convert to clipspace from homogeneous

		//apply a tiny bias to its z before converting to clip-space
		proj.z = (proj.z - 0.005) / proj.w;
		proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]

		//read p true depth
		float pdepth = texture( u_depth_texture, proj.xy ).x;

		//compare true depth with its depth
		if( pdepth < proj.z ) //if true depth smaller, is inside
			num--; //remove this point from the list of visible
	}

	//finally, compute the AO factor accordingly
	float ao = float(num) / float(samples);


	FragColor = vec4(ao);
	
}


\blur.fs

#version 330 core

uniform vec2 u_offset;
uniform sampler2D u_texture;
in vec2 v_uv;
out vec4 FragColor;

void main()
{	
	vec2 uv = v_uv;
	vec4 color = vec4(0.0);
	for(int i = -2; i<= 2; ++i)
	for(int j = -2; j<= 2; ++j)
		color += texture2D(u_texture,uv + u_offset * vec2(i,j) + vec2(0.5) *u_offset);
	color /= 25.0;
	FragColor = vec4(color);
}